{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze data\n",
    "\n",
    "Includes plotting single runs, comparing multiple runs, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Graphing training runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# Simply update this with the .jsonl files you want to plot\n",
    "train_models = ['dataset_3_1_1']\n",
    "train_models = ['trained_models/' + trained_model_folder for trained_model_folder in train_models]\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "for trained_model_folder in train_models:\n",
    "    latest_file = None\n",
    "    latest_time = None\n",
    "    \n",
    "    for file in glob.glob(os.path.join(trained_model_folder, \"train_*.jsonl\")):\n",
    "        filename = os.path.basename(file)\n",
    "        parts = filename.replace(\"train_\", \"\").replace(\".jsonl\", \"\").split(\"-\")\n",
    "        month, day, year, hour, minute, second = map(int, parts)\n",
    "        \n",
    "        # Convert to datetime object\n",
    "        file_time = datetime.datetime(year, month, day, hour, minute, second)\n",
    "        \n",
    "        # Find the latest file\n",
    "        if latest_time is None or file_time > latest_time:\n",
    "            latest_time = file_time\n",
    "            latest_file = file\n",
    "            \n",
    "    train_data_x = []\n",
    "    \n",
    "    with open(latest_file, 'r') as data_file:\n",
    "        for line in data_file:\n",
    "            jdata = json.loads(line)\n",
    "            if jdata['message'] == \"Training progress\" and 'iter' in jdata:\n",
    "                train_data_x.append([jdata['iter'], jdata['train_loss'], jdata['val_loss']])\n",
    "\n",
    "    x = [point[0] for point in train_data_x]\n",
    "    tl = [point[1] for point in train_data_x]\n",
    "    vl = [point[2] for point in train_data_x]\n",
    "\n",
    "    plt.plot(x, tl, linestyle='-', label=f'Training Loss')\n",
    "    plt.plot(x, vl, linestyle='-', label=f'Validation Loss')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Training Progress for Multiple Datasets')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Graphing sampling (distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "\n",
    "output_dir_name = 'dataset_1_1'\n",
    "\n",
    "def get_latest_folder():\n",
    "    latest_time = None\n",
    "    latest_file = None\n",
    "    for file in glob.glob(os.path.join('generated_samples', output_dir_name, \"*\")):\n",
    "        filename = os.path.basename(file)\n",
    "        parts = filename.split(\"-\")\n",
    "        month, day, year, hour, minute, second = map(int, parts)\n",
    "        \n",
    "        # Convert to datetime object\n",
    "        file_time = datetime.datetime(year, month, day, hour, minute, second)\n",
    "        \n",
    "        # Find the latest file\n",
    "        if latest_time is None or file_time > latest_time:\n",
    "            latest_time = file_time\n",
    "            latest_file = file\n",
    "    return latest_file\n",
    "\n",
    "input_dist_path = f'{get_latest_folder()}/input_leading_particles.csv'\n",
    "sample_dist_path = f'{get_latest_folder()}/sampled_leading_particles.csv'\n",
    "\n",
    "columns = [\"num_particles\", \"pdgid\", \"e\", \"px\", \"py\", \"pz\"]\n",
    "bin_settings = {\n",
    "    \"num_particles\": {\"min\": 5, \"max\": 20, \"bins\": 15, \"ymin\": 0, \"ymax\": 2000},\n",
    "    \"pdgid\": {\"min\": -300, \"max\": 0, \"bins\": 10, \"ymin\": 0, \"ymax\": 10000},\n",
    "    \"e\": {\"min\": 0, \"max\": 35000, \"bins\": 35, \"ymin\": 0, \"ymax\": 10000},\n",
    "    \"px\": {\"min\": 0, \"max\": 35000, \"bins\": 20, \"ymin\": 0, \"ymax\": 2000},\n",
    "    \"py\": {\"min\": 0, \"max\": 35000, \"bins\": 20, \"ymin\": 0, \"ymax\": 2000},\n",
    "    \"pz\": {\"min\": 0, \"max\": 35000, \"bins\": 20, \"ymin\": 0, \"ymax\": 2000},\n",
    "}\n",
    "\n",
    "df1 = pd.read_csv(input_dist_path, sep=\" \", names=columns, engine=\"python\")\n",
    "df2 = pd.read_csv(sample_dist_path, sep=\" \", names=columns, engine=\"python\")\n",
    "\n",
    "for column, settings in bin_settings.items():\n",
    "    min_val = settings[\"min\"]\n",
    "    max_val = settings[\"max\"]\n",
    "    bins = settings[\"bins\"]\n",
    "    ymin = settings[\"ymin\"]\n",
    "    ymax = settings[\"ymax\"]\n",
    "\n",
    "    # Filter values to ensure they fall within the specified range\n",
    "    filtered_data1 = df1[column][(df1[column] >= min_val) & (df1[column] <= max_val)]\n",
    "    filtered_data2 = df2[column][(df2[column] >= min_val) & (df2[column] <= max_val)]\n",
    "\n",
    "    # Create side-by-side histograms\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    # First file histogram\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(filtered_data1, bins=bins, range=(min_val, max_val), edgecolor=\"black\", alpha=0.7, color=\"blue\")\n",
    "    plt.title(f\"Histogram of {column} - Input leading particle\")\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.ylim(ymin, ymax)  # Set y-axis limits\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "    \n",
    "    # Second file histogram\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(filtered_data2, bins=bins, range=(min_val, max_val), edgecolor=\"black\", alpha=0.7, color=\"orange\")\n",
    "    plt.title(f\"Histogram of {column} - Sampled leading particle\")\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.ylim(ymin, ymax)  # Set y-axis limits\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "    \n",
    "    # Display the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "\n",
    "output_dir_name = 'dataset_3_1_1'\n",
    "\n",
    "def get_latest_folder():\n",
    "    latest_time = None\n",
    "    latest_file = None\n",
    "    for file in glob.glob(os.path.join('generated_samples', output_dir_name, \"*\")):\n",
    "        filename = os.path.basename(file)\n",
    "        parts = filename.split(\"-\")\n",
    "        month, day, year, hour, minute, second = map(int, parts)\n",
    "        \n",
    "        # Convert to datetime object\n",
    "        file_time = datetime.datetime(year, month, day, hour, minute, second)\n",
    "        \n",
    "        # Find the latest file\n",
    "        if latest_time is None or file_time > latest_time:\n",
    "            latest_time = file_time\n",
    "            latest_file = file\n",
    "    return latest_file\n",
    "\n",
    "input_dist_path = f'{get_latest_folder()}/input_leading_particles.csv'\n",
    "sample_dist_path = f'{get_latest_folder()}/sampled_leading_particles.csv'\n",
    "\n",
    "columns = [\"num_particles\", \"pdgid\", \"e\", \"px\", \"py\", \"pz\"]\n",
    "bin_settings = {\n",
    "    \"num_particles\": {\"min\": 5, \"max\": 20, \"bins\": 15, \"ymin\": 0, \"ymax\": 2000},\n",
    "    \"pdgid\": {\"min\": -300, \"max\": 0, \"bins\": 10, \"ymin\": 0, \"ymax\": 10000},\n",
    "    \"e\": {\"min\": 0, \"max\": 35000, \"bins\": 35, \"ymin\": 0, \"ymax\": 10000},\n",
    "    \"px\": {\"min\": 0, \"max\": 35000, \"bins\": 20, \"ymin\": 0, \"ymax\": 2000},\n",
    "    \"py\": {\"min\": 0, \"max\": 35000, \"bins\": 20, \"ymin\": 0, \"ymax\": 2000},\n",
    "    \"pz\": {\"min\": 0, \"max\": 35000, \"bins\": 20, \"ymin\": 0, \"ymax\": 2000},\n",
    "}\n",
    "\n",
    "df1 = pd.read_csv(input_dist_path, sep=\" \", names=columns, engine=\"python\")\n",
    "df2 = pd.read_csv(sample_dist_path, sep=\" \", names=columns, engine=\"python\")\n",
    "\n",
    "for column, settings in bin_settings.items():\n",
    "    min_val = settings[\"min\"]\n",
    "    max_val = settings[\"max\"]\n",
    "    bins = settings[\"bins\"]\n",
    "    ymin = settings[\"ymin\"]\n",
    "    ymax = settings[\"ymax\"]\n",
    "\n",
    "    # Filter values to ensure they fall within the specified range\n",
    "    filtered_data1 = df1[column][(df1[column] >= min_val) & (df1[column] <= max_val)]\n",
    "    filtered_data2 = df2[column][(df2[column] >= min_val) & (df2[column] <= max_val)]\n",
    "\n",
    "    plt.figure(figsize=(21, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(filtered_data1, bins=bins, range=(min_val, max_val), edgecolor=\"black\", alpha=0.7, color=\"blue\", label=\"Input\")\n",
    "    plt.hist(filtered_data2, bins=bins, range=(min_val, max_val), edgecolor=\"black\", alpha=0.7, color=\"orange\", label=\"Sampled\")\n",
    "    plt.title(f\"Histogram of {column}\")\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.ylim(ymin, ymax)\n",
    "    plt.legend()\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
